# Diffusion Lab

A Python application and creative toolkit for generating storyboards, single-image art, and more using Stable Diffusion and AI-powered features.

# ![License](https://img.shields.io/github/license/arun-gupta/diffusion-lab)
# ![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)

# Table of Contents
- [Main Features](#main-features)
- [Configurable Options](#configurable-options)
- [Quick Start Example](#quick-start-example)
- [Screenshot](#screenshot)
- [How It Works](#how-it-works)
- [Usage](#usage)
- [Installation](#installation)
- [Directory Structure](#directory-structure)
- [Planned Features](#planned-features)
- [Troubleshooting](#troubleshooting)
- [License](#license)

## Main Features

- **Storyboard Mode:** Generate a 5-panel storyboard from a scene description, with AI-generated images and captions.
- **Single-Image Art Mode:** Generate a single, high-quality AI image from a prompt in your chosen style.
- **Export:** Save storyboards as PDF or images.

## Configurable Options

- **Style Options:** Choose from different visual styles (cinematic, anime, noir, etc.).
- **Demo/AI Mode Toggle:** Choose between fast demo mode (placeholder images) and full AI mode (real Stable Diffusion/StableLM generation) using the toggle above the generation type selector.

## Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/arun-gupta/diffusion-lab.git
   cd diffusion-lab
   ```

2. **Create a virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the application**:

   **Option A: Web Application (Recommended)**
   ```bash
   python3 diffusionlab/api/webapp.py
   # Then open http://localhost:5001 in your browser
   ```

   **Option B: Gradio Interface**
   ```bash
   python diffusionlab/tasks/storyboard.py
   # Then open http://localhost:7860 in your browser
   ```

   **Option C: Demo Version**
   ```bash
   python diffusionlab/tasks/demo.py
   ```

## Quick Start Example

```bash
# 1. Start the web application from the project root
python3 -m diffusionlab.api.webapp

# 2. Open your browser and go to:
http://localhost:5001

# 3. Enter a prompt, e.g.:
#   "A robot wanders a post-apocalyptic desert searching for signs of life"
# 4. Select your desired mode and style, then click Generate.
```

## Screenshot

![Diffusion Lab Main UI](docs/main-ui.png)

## Example Outputs

Here are some sample results generated by Diffusion Lab:

**Storyboard Example:**
**Prompt:**
A detective walks into a neon-lit alley at midnight, rain pouring down
**Style:**
Cinematic
![Sample Storyboard](docs/sample-storyboard.png)

**Single-Image Art Example:**
**Prompt:**
A spaceship crew encounters an alien artifact on a distant planet
**Style:**
Pixar
![Sample Art](docs/sample-art.png)

<!--
To add your own examples, place images in the docs/ directory and update the paths above.
-->

## How It Works

1. **User Input:**
   - The user enters a scene description or art prompt in the web UI and selects the desired mode (Storyboard or Single-Image Art), style, and Demo/AI mode.
2. **Request Sent to Backend:**
   - The frontend sends the input to the Flask backend via an AJAX request.
3. **AI Model Processing:**
   - In Demo mode, the backend generates placeholder images and captions.
   - In AI mode, the backend uses Stable Diffusion XL (for images) and StableLM (for captions) to generate real, high-quality outputs based on the prompt and style.
4. **Output Generation:**
   - The backend assembles the images (and captions, if storyboard) into a single output image (storyboard or single art piece).
5. **Result Displayed:**
   - The generated image is sent back to the frontend and displayed in the UI, where the user can view or download it.

<!-- Optional: Simple diagram (text-based) -->
```
User Input → [Frontend] → /generate → [Flask Backend]
    └─> [Demo Mode] → Placeholder Images
    └─> [AI Mode] → Stable Diffusion XL + StableLM
        └─> Output Image(s) → [Frontend Display]
```

## Usage

### Web Application (Recommended)
1. Open your browser and go to `http://localhost:5001`
2. Select either **Storyboard** or **Single-Image Art** mode
3. Use the Demo/AI toggle to choose between fast demo mode and full AI mode
4. Enter your scene description or art prompt in the text box
5. Choose your preferred style from the dropdown
6. Click "Generate"
7. Download the PNG file or view the results

**Note:** Generated images are saved locally in the `static/storyboards/` directory.

### Gradio Interface
1. Open your browser and go to `http://localhost:7860`
2. Enter your scene description in the text box
3. Choose your preferred style from the dropdown
4. Click "Generate Storyboard"
5. Wait for the AI to generate your 5-panel storyboard
6. Download or view the results

## Example Inputs

- "A detective walks into a neon-lit alley at midnight, rain pouring down"
- "A robot wanders a post-apocalyptic desert searching for signs of life"
- "A young wizard discovers an ancient library hidden in the mountains"

## Technical Details

### Web Application
- **Backend**: Flask web framework with RESTful API
- **Frontend**: Modern HTML5/CSS3/JavaScript with Bootstrap 5
- **Image Processing**: PIL/Pillow for image generation and manipulation
- **Real-time Updates**: AJAX-powered interface with progress tracking

### Gradio Interface
- **Image Generation**: Uses Stable Diffusion XL for high-quality image generation
- **Caption Generation**: Uses StableLM for contextual descriptions
- **UI Framework**: Gradio for a clean, web-based interface
- **Export**: PDF generation with reportlab

## Requirements

- Python 3.8+
- CUDA-compatible GPU (recommended for faster generation)
- 8GB+ RAM
- Internet connection for model downloads

## Planned Features

- **1. Image-to-Image (img2img):** Transform sketches, photos, or rough concepts into polished art.
- **2. Inpainting (Content-aware Fill):** Remove or replace parts of an image by masking them and describing what should go there.
- **3. Outpainting (Image Expansion):** Extend the borders of an image with new, contextually appropriate content.
- **4. Style Transfer:** Apply the style of one image (e.g., a famous painting) to another image.
- **5. Prompt Chaining / Story Evolution:** Generate a sequence of images that evolve based on a series of prompts.
- **6. Batch Generation & Variations:** Generate multiple variations for a single prompt to explore creative diversity.
- **7. Animated Diffusion (Frame Interpolation):** Create short animations by generating frames that morph between prompts or images.
- **8. DreamBooth / Custom Subject Training:** Fine-tune Stable Diffusion on a small set of images of a person, pet, or object, so you can generate that subject in any context.
- **9. Text-Guided Image Editing:** Edit an existing image by describing the change in text.
- **10. Super-Resolution / Image Enhancement:** Upscale low-resolution images or enhance details using diffusion-based super-resolution models.
- **11. AI Avatars and Profile Pictures:** Generate unique avatars or profile pictures in various styles from a photo or prompt.
- **12. AI Art Gallery / Curation:** Curate and display the best generations, or let users vote on their favorites.
- **13. API Playground:** Let users experiment with all Stable Diffusion parameters (guidance scale, steps, seed, etc.).
- **14. Prompt Engineering Tools:** Help users craft better prompts with suggestions, negative prompts, and prompt templates.
- **15. Model Comparison:** Let users compare outputs from different Stable Diffusion checkpoints or custom models.

## License

This project is licensed under the Apache License 2.0 - see the LICENSE file for details. 

## Directory Structure

```
diffusion-lab/
├── diffusionlab/
│   ├── __init__.py
│   ├── config.py
│   ├── utils.py
│   ├── setup.py
│   ├── requirements.txt
│   ├── static/
│   ├── templates/
│   ├── api/
│   │   ├── __init__.py
│   │   └── webapp.py
│   └── tasks/
│       ├── __init__.py
│       ├── storyboard.py
│       └── demo.py
├── tests/
│   └── test_installation.py
├── README.md
├── LICENSE
├── QUICKSTART.md
├── WEBAPP_README.md
├── run_webapp.sh
├── run.sh
├── run.bat
├── requirements.txt
├── setup.py
```

- **diffusionlab/**: Main package code, feature modules, static assets, templates, and API logic
- **tests/**: Test scripts
- **README.md, LICENSE, QUICKSTART.md, etc.**: Top-level documentation and legal files
- **run_*.sh, run.bat**: Entrypoint scripts 

## Troubleshooting

### Static Files Not Loading (JS/CSS 404)
- **Symptom:** The UI is broken, or clicking Generate does nothing. Browser console shows 404 for /static/js/app.js or /static/css/style.css.
- **Solution:**
  - Make sure you run the app from the project root with:
    ```bash
    python3 -m diffusionlab.api.webapp
    ```
  - Ensure Flask is configured with the correct static and template folder paths and `static_url_path='/static'`.

### AI Mode Not Available / ImportError
- **Symptom:** Error message: "AI mode is not available. Please ensure diffusionlab/tasks/storyboard.py and dependencies are present."
- **Solution:**
  - Make sure all imports in your code use absolute package paths (e.g., `from diffusionlab.config import *`).
  - Run the app from the project root.
  - Check for typos or missing files in the `diffusionlab/tasks/` directory.

### Accessibility Warning: aria-hidden and Focus
- **Symptom:** Browser console warning: "Blocked aria-hidden on an element because its descendant retained focus..."
- **Solution:**
  - This is a warning, not an error. The app will still work.
  - The app moves focus to the Generate button when the modal closes to improve accessibility.

### No /generate Request When Clicking Generate
- **Symptom:** Nothing happens when clicking Generate, and no request appears in Flask logs.
- **Solution:**
  - Check that `app.js` is loaded (no 404 in Network tab).
  - Check for JavaScript errors in the browser console.
  - Ensure the form and button IDs in the HTML match those in the JS.

### General Tips
- Always run the app from the project root.
- If you make structural changes, restart the Flask server.
- For more help, check the browser console, Flask logs, and the [Issues](https://github.com/arun-gupta/diffusion-lab/issues) page.

### How to Check Flask Logs
- When running the app, watch the terminal for error messages or tracebacks after you perform an action in the UI (like clicking Generate).
- 500 errors or ImportErrors will be shown here and can help pinpoint the problem.

### How to Use Browser Developer Tools
- **Open Developer Tools:** Press F12 or right-click and select "Inspect" in your browser.
- **Console Tab:** Shows JavaScript errors, warnings, and logs. Red errors here often indicate why the UI is not working.
- **Network Tab:** Shows all network requests. Look for 404s (missing files) or 500s (server errors) when you click Generate or load the page.
- **Tip:** If you see a request to `/generate` with a 500 error, check the Flask logs for the cause. 